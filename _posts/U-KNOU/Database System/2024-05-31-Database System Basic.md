---
title: "[U-KNOU] 데이터베이스 시스템"
description: "[U-KNOU] 데이터베이스 시스템"
date: 2024-05-28
categories: [ U-KNOU, Database System ]
tags: [ U-KNOU, Database System ]
---

# 1강. 데이터베이스의 이해 

- 데이터의 단위  
  - bit < byte < KB(kilobyte) < MB(megabyte) < GB(gigabyte) < TB(terabyte) < PB(petabyte) < EB(exabyte) < ZB(zettabyte) < YB(yottabyte)  

### 파일처리 시스템  

- 파일처리 시스템  
  - 데이터베이스 개발 전 데이터 관리에 사용  
  - 업무 별 애플리케이션이 개별 데이터를 데이터 파일에 저장/관리하는 시스템  
  
- 파일처리 시스템 문제점  
  - 데이터 종속의 문제
  - 데이터 중복의 문제
    - 일관성: 특정 데이터 수정 시 중복되는 모든 데이터를 수정해야 한다. 
    - 보안성: 같은 데이터에 같은 수준의 보안 유지 필요
    - 경제성
  - 무결성 훼손의 문제
    - 데이터의 정확성을 보장하지 않는다. 
    - 데이터의 값과 값에 대한 제약조건을 동시에 만족하지 못한다.  
  - 동시 접근의 문제

### 데이터베이스 특징

  - 자기 기술성(자신이 어떤 데이터를 다루고 있는지 인지)
  - 프로그램과 데이터의 격리 및 추상화
  - 다중 뷰 제공: 사용자가 관심을 갖는 데이터베이스의 일부만 표현할 수 있다.  
  - 데이터 공유와 다수 사용자 트랜잭션 처리
    - 다수의 데이터 조작 요청을 동시성 제어 기능을 통해 데이터 일관성 보장 및 동시 작업 수행 가능
    - 한 트랜잭션이 끝날 때까지 다른 트랜잭션은 해당 데이터에 대한 접근을 막는다.  
    - `트랜잭션`: 하나의 논리적 작업을 처리하기 위한 일련의 데이터베이스 명령의 집합  
  
- 데이터: 하나의 값에 2개 이상의 설명이 있는 것  
- 메타데이터: 값에 대한 부연설명  
- 데이터베이스: 애플리케이션 시스템에서 사용되는 데이터의 집합
- DBMS(Database Management System): 데이터베이스에 저장된 데이터의 구성, 저장, 관리, 사용을 위한 소프트웨어 패키지
- 데이터베이스 시스템: 정보를 데이터베이스에 저장, 관리하여 사용자에게 요구된 형태의 정보로 제공하는 컴퓨터 기반 시스템
  
- 시스템 카탈로그(=데이터 사전)
  - 특정 데이터베이스에 저장된 파일 구조를 파악하기 위한 데이터 타입/포맷/물리적 정보/데이터의 의미, 설명 등 논리적 정보를 관리 

### DBMS 3단계 구조

<img src="/assets/img/knou_database_system/schema.png" width="600px">  
  
- `내부단계`   
  - 데이터가 어디에 어떻게 저장되어 있는지와 같이 `데이터의 물리적인 저장 방식`을 관리      
- `개념단계`    
  - 전체 데이터베이스의 구조와 데이터 간의 관계를 정의   
  - 물리적인 상세사항은 배제
  - 메타데이터를 사용하여 데이터의 규모, 구조, 의미 등을 명시   
  - 보안성, 무결성 검사
- `외부단계`   
  - 사용자 또는 응용 프로그램이 데이터에 접근하는 방식을 정의  
  - 사용자가 관심 갖는 데이터베이스의 일부만 기술(다른 부분은 은폐)
- `외부-개념사상`   
  - 논리적 데이터 독립성: 개념 스키마에 변화 → 외부-개념 사상에만 반영(외부 스키마 영향 x)
- `개념-내부사상`   
  - 개념 단계 데이터 스키마가 디스크 내 내부 필드와 어떻게 대응하는가를 정의
  - 물리적 데이터 독립성: 다른 디스크로의 데이터 이동 / 파일 구조 변경 등 물리적 변화가 발생해도 개념-내부 사상에만 반영(개념 스키마에 영향 x)  
  
- `DBMS 3단계 구조의 특징`  
  - 데이터의 물리적인 저장 방식과 사용자의 데이터 접근 방식 사이의 독립성을 보장   
  - 사용자는 데이터의 물리적인 저장 방식을 몰라도 데이터에 접근하고 사용  
  - 데이터의 물리적인 저장 방식이 변경되더라도 사용자의 데이터 접근 방식에는 영향을 미치지 않음  

### 데이터베이스 언어

- 데이터 정의 언어(DDL: Data Definition Language)   
  - 데이터베이스 객체를 생성, 수정, 삭제하기 위한 언어  
  - 데이터의 논리적 구성이나 특징을 규정  
  - 데이터가 기억장치에 저장되도록 데이터의 물리적 구성을 규정  
  - 데이터의 물리적 구성과 논리적 구성간의 사상을 규정  
  
- 데이터 조작 언어(DML: Data Manipulation Language)  
	- 구조화된 데이터에 사용자가 접근 및 조작할 수 있도록 지원하는 언어  
	- 사용자의 요청을 시스템 내부에서 효율적으로 처리 가능  

### 데이터베이스 시스템 아키텍처

- 중앙집중식 방식
  - 단일 서버가 다수의 클라이언트 장치를 대신하여 작동
  - 중앙 컴퓨터의 과부하로 전체적인 성능 저하
- 분산 시스템 방식
  - 클라이언트-서버 데이터베이스 시스템
  - 애플리케이션 프로그램의 부하를 분산
  - 소프트웨어의 유지보수 비용을 절감 및 이식성 증가

<br/>
<hr>

# 2강. 데이터베이스 모델링

### 데이터베이스 모델링 이해

- 비지니스 관점: 어떤 데이터를 저장해야 하는가?  
- 컴퓨터 프로그래머 관점: 어떻게 데이터를 저장해야 하는가?  
  
<img src="/assets/img/knou_database_system/modeling.png" width="600px">   
  
- 데이터 모델
  - 데이터베이스 구조 명시
  - 의미, 데이터 타입, 연산 등을 명시하기 위해 사용할 수 있는 개념들의 집합  
- 데이터 모델링
  - 실세계의 일부분을 DBMS가 지원하는 데이터 모델의 형태로 나타내는 과정  
  - 데이터에 대한 요구사항을 정의, 분석, 추상화하는 과정
  1. 개념적 데이터 모델링(어떤 데이터를 저장할 것인가?)  
    - 사용자의 요구사항의 분석  
    - 실세계의 데이터를 개념적으로 일반화하여 데이터 구조, 데이터 타입, 속성, 관계, 제약조건 등을 이끌어내는 과정  
  2. 논리적 데이터 모델링(저장할 데이터를 DBMS에 어떻게 저장할 것인가?)  
    - 개념적 데이터 모델링을 통해 만들어진 결과물을 특정 DBMS에 저장할 수 있는 모델로 변환시키는 작업  
  3. 물리적 데이터 모델링  
    - 데이터베이스 파일의 내부 저장구조, 파일 구성, 인덱스, 접근 경로 등을 결정하는 과정  
▶ 1 ~ 3 과정을 거쳐 내부 스키마가 만들어진다.  

### 사용자 요구사항 분석

- 제안요청서(RFP: Request For Proposal) → **요구사항 도출** → 요구사항 명세서 → **요구사항 분석** → 요구사항 정의서 → **요구사항 기록**  
  
- 요구사항 도출  
  - 구축대상, 프로젝트 목표, 범위를 기준으로 조사범위를 결정  
  - 업무관계자 인터뷰  
  - 외부자료 수집 및 분석  
- 요구사항 분석  
  - 도출된 요구사항의 명확성, 완전성, 모호성 검증  
  - 불완전한 부분이 존재할 경우 요구사항 도출단계 재수행  
  - 요구사항을 분류하여 통합 또는 분리  
- 요구사항 기록  
  - 요구사항 목록 정리 및 관리자의 승인  
  - 정리된 요구사항을 형식에 맞춰 문서화  
  - 프로젝트 종료 때까지 반영 여부 지속적 관리  

### ER 모델

- ER 모델의 개념  
  - P.Chen 박사 제안  
  - 실세계 속성으로 이루어진 `개체(Entity)`와 개체 사이의 `관계(Relationship)`를 정형화시킨 모델  
  - `개념적 모델링 단계`에서 사용되는 데이터 모델  
  - 데이터 구조와 관계를 ER다이어그램(ERD)으로 표현  
  - 구성요소: 개체집합, 관계집합, 속성  
  
- 개체(Entity)   
  - 실세계에 존재하는 다른 객체와 구별되는 유무형의 사물  
  - 개체를 설명하는 여러 속성으로 구성  
- 개체집합(Entity Set): 같은 속성을 공유하는 개체들의 모임  
  
- 관계: 개체와 개체 사이의 연관성  
- 관계집합: 개체 집합 간의 연결 관계  
  
- 속성(컬럼)
  - 개체를 구체적으로 설명
  - 속성의 종류  
    - 단순 속성: 더 작은 구성요소로 나눌 수 없는 속성(이름, 성별, 나이)  
    - 복합 속성  
      - 더 작은 요소로 나눌 수 있는 속성(생년월일, 년/월/일)  
      - 들여쓰기로 구분  
        생년월일  
          년  
          월  
          일  
    - 단일값 속성: 한 개체에 대해 단 하나의 값만을 갖는 속성(주민번호 등..)  
    - 다중값 속성  
      - 한 개체에 대해 여러 개의 값을 갖는 속성  
      - 예: {전화번호}  
    - 유도 속성  
      - 다른 속성의 값으로부터 값이 유추될 수 있는 속성   
      - 예: 나이(생년월일로 유추가 가능)  
    - 저장 속성: 유도 속성을 위해 사용될 수 있는 속성  
  
- 정리
  - 개체(entity): 데이터의 한 행  
  - 개체집합(entity set): 테이블  
  - 속성: 컬럼  
  - 생년월일의 속성: 복합 속성 && 단일값 속성 && 유도 속성  
  
- <img src="/assets/img/knou_database_system/0.jpg" width="800px">  

### 제약조건

- ER모델은 개체와 관계에 대한 표현의 정확성을 위해 데이터가 준수해야하는 제약조건을 정의할 수 있는 표현 방법을 제공한다.  
  
- 제약조건의 종류  
  1. 사상수(Mapping Cardinality): 관계집합에 참가한 개체집합에 대해 한 개체가 다른 개체와 관계를 맺을 수 있는 수량을 명시  
    - <img src="/assets/img/knou_database_system/1.jpg" width="400px">
    - 일대일(1:1)
    - 일대다(1:N)
    - 다대일(N:1)
    - 다대다(N:N)
    width="600px">  
  2. 참가 제약 조건(Participation Constraints)  
    - <img src="/assets/img/knou_database_system/2.jpg" width="400px">  
    - 전체적 참가: 어떤 개체집합의 모든 개체가 관계집합에 참여하는 조건(과목개체집합)
    - 부분적 참가: 어떤 개체집합의 일부 개체가 관계집합에 참여하는 조건(교수개체집합)  
  3. 키 속성  
    - 각 개체를 구별하는데 사용되는 유일한 값을 가지는 속성의 집합
    - 개체를 고유하게 구분하는 역할
    - 관계 집합의 특정 관계를 찾는 사람
  4. 특수 속성과 특수 관계  
    - <img src="/assets/img/knou_database_system/mapping2.jpg" width="400px">
    - `관계집합의 속성`: 두 개체집합의 관계에서 생성되는 값을 저장하는 속성(신청시각)
    - 재귀적 관계: 한 개체집합이 자기 자신과 집합을 형성하는 관계(선수과목)  
    
    - <img src="/assets/img/knou_database_system/3.jpg" width="400px">  
    - <u>학생 개체집합과 계좌 개체집합이 보유 관계집합으로 연결되어 있을 경우</u>
      - `약한 개체집합`(== 계좌 개체집합)
        - 개체의 존재 유무가 관계를 맺고 있는 개체의 존재에 종속되는 개체집합
      - `강한 개체집합`(== 학생 개체집합)
        - 약한 개체집합과 연결되는 일반 개체집합
        - 계좌 개체가 삭제되어도 학생 개체는 삭제될 필요없다. 

<br/>
<hr>

# 3강. 관계형 모델

### 관계형 모델의 개념

- 논리적 데이터 모델링 단계
  1. DBMS에서 사용하는 데이터 모델에 맞추어 데이터를 표현하는 과정
  2. 데이터 정의 언어(DDL)로 기술된 개념 스키마 생성
  3. 관계형 모델(Relational Model)
    - 에드가 F.코드(1969년)
    - 릴레이션으로 데이터를 표현하는 모델
    - 데이터 표현이 단순하고 직관적 구조화 모델
    - 현재 대다수 DBMS의 기초

### 릴레이션

- 릴레이션의 구성
  - `릴레이션`: 표 형태의 구성
  - 스키마: 모든 컬럼
  - 컬럼: 속성, 필드
  - 행: 레코드, 투플
  - 여러 행: 인스턴스
  - 카디널리티: 레코드의 개수
  
- 릴레이션의 특징
  - 레코드의 유일성: 중복된 레코드 존재 불가
  - 레코드의 무순서성: 레코드의 순수는 의미 없음
  - 컬럼의 무순서성: 컬럼은 순서가 없고 이름과 값의 쌍
  - 컬럼 값의 원자성: 모든 컬럼값들은 나눌 수 없는 단 하나의 의미  
    예: 컬럼값이 {사과, 바나나, 수박} 이런 형식으로 들어가지 않는다.  
  
- 키의 종류
  - 슈퍼키(Super Key): 유일성(Unique) 만족
  - 후보키(Candidate Key): 유일성 & 최소성 만족
  - 기본키(PK: Primary Key): 레코드 구분을 위해 선택된 후보키
  - 외래키(FK: Foreign Key): 참조된 다른 릴레이션의 기본키
  
- 관계형 모델의 제약조건
  - 영역 제약조건: 컬럼에 정의된 영역(Domain)에 속한 값으로만 컬럼값이 결정
  - 키 제약조건: 키는 레코드를 고유하게 구별하는 값으로 구성
  - 개체 무결성 제약조건: 기본키의 값 null 불가
  - 참조 무결성 제약조건: 다른 레코드의 기본키만 참조가능
  
- <img src="/assets/img/knou_database_system/4.jpg" width="400px">  
  - 일대다
  - 과목 개체집합은 모든 개체가 관계집합에 참여하는 전체적 참가(===== 두 줄로 표현)
  - 전체적 참가하는 과목 개체집합에 FK 생성(교수번호)
  - <img src="/assets/img/knou_database_system/6.jpg" width="600px"> 
  - 다대다
  - `다대다 관계에서는 새로운 릴레이션 생성 필요`
  - 새 릴레이션 구성 {학생번호(PK, FK), 과목번호(PK, FK), 신청시각}
  
- <img src="/assets/img/knou_database_system/3.jpg" width="400px"> 
  - 일대일
  - 보유 관계집합: 약한 관계집합(2중선)
  - 계좌 개체집합: 약한 개체집합
  - `일대일 관계`에서는 양쪽 다 외래키 존재가능하지만 보통 `컬럼 수가 적은 곳에 외래키 위치`
  - `약한 개체집합에서 참조된 외래키`는 기본키로 추가되어 `복합키`를 이룬다. 
    - 학생 릴레이션{학생번호(PK), 학생이름, 성별 ...}
    - 계좌 릴레이션{계좌번호(PK), 잔액, 학생번호(PK, FK)}
    - 복합키로 설정을 하면 학생이 전학을 갔을 때, 학생 릴레이션에서 삭제되고 계좌 릴레이션에서 학생번호는 PK이기 때문에 무조건 같이 삭제되어야 한다.

### 데이터 연산

- 관계연산의 개념
  - 관계형 모델을 기반으로 구성된 릴레이션을 사용하여 새로운 릴레이션을 생성하는 표현
  - 사용자의 관점에서 필요한 데이터를 릴레이션에서 추출하는 방법을 제공하는 도구
  - `관계 대수(relational algebra)`
    - 관계 연산을 정의하는 방법
    - 주어진 릴레이션에서 필요한 릴레이션을 만드는 연산자로 구성
      (σ, π, ×, -, ∪, ∩, ⋈ ..)
    - 관계 대수 연산자는 새로운 임시 릴레이션을 생성
    - 연산자를 중첩하여 연산 처리 절차를 표현
  
- `σ(Selection) 셀렉트 연산`: 레코드(행) 단위로 데이터를 가져온다.
  - <u>σ소속학과 = ‘컴퓨터과학과’ (교수)</u>  
    교수테이블 내 소속학과가 컴퓨터학과인 데이터 조회  
  - σ소속학과 = ‘컴퓨터과학과’∧연봉>=50000000 (교수)  
	  교수테이블 내 소속학과가 컴퓨터학과이고 연봉이 5천만원 이상인 데이터 조회
	  - ∧ == and 
	  - ∨ == or
- `π(Projection) 프로젝트 연산`: 기술된 컬럼만 가져온다.
  - π교수이름, 소속학과 (교수)  
	  교수테이블 내 컬럼명이 교수이름과 소속학과인 데이터를 가져온다.  
  - π 교수이름 ( σ직위 = ‘부교수’ (교수) )  
    직위가 ‘부교수’인 교수의 교수이름을 출력  

### 집합 연산자

- A∪B 합집합 / A∩B 교집합 / A-B 차집합
- 릴레이션은 집합, 레코드(행)는 집합에 포함된 원소
- 집합 연산자 사용 조건
  - 두 릴레이션의 차수(컬럼의 수)가 동일해야한다. 
  - 두 컬럼의 도메인(영역: 데이터타입)이 일치해야한다.
  
- 카티시언 프로덕트 연산: 두 릴레이션을 하나의 릴레이션으로 결합
- <img src="/assets/img/knou_database_system/5.jpg" width="400px"> 
  
- 조인 연산: 조건에 만족하는 레코드들만 결합
- <img src="/assets/img/knou_database_system/7.jpg" width="400px"> 
  
- Quiz 1. ‘컴퓨터과학과’ 소속의 교수가 강의하는 과목의 과목명과 과목코드는?
  - 카티시언 프로덕트 사용
    - π 과목명, 과목코드 ( σ 교수.소속 = ‘컴퓨터과학과’ ( σ 과목.교수번호 = 교수.교수번호 ( 과목 x 교수 ) ) )
  - 조인연산 사용
    - π 과목명, 과목코드 (  σ 교수.소속 = ‘컴퓨터과학과’ ( 과목 ⋈ 과목.교수번호 = 교수.교수번호 교수 ) )
  
- 집계 함수 연산
  - Quiz 2. 과목명의 개수는?
    - F count(과목명) (과목)
  - Quiz 3. 각 학과에 소속된 교수는 몇명일까?
	  - 소속학과 G 소속학과, count(*) (교수)
	  - == select 소속학과, count(*) from 교수 group by 소속학과;

<br/>
<hr>

# 4강~6강. SQL

### SQL의 개요

- Structured Query Language 은 관계대수에 기초하여  RDBMS  의 데이터 관리를 위해 설계된 언어.
- 1986년 ANSI
- 1987년 ISO 표준으로 제정
- 비절차적 언어: 필요한 것만 간단하게 가져올 수 있다. 
- 인간의 언어와 매우 유사하고 간단, 명료하다. 

### 데이터배이스 언어

- `데이터베이스 정의 언어(DDL: Data Definition Language)`	
  - 데이터베이스 내 `객체를 생성 및 삭제`하고 그 `구조를 조작`하는 명령어의 집합
    - 데이터베이스 객체의 종류
      - 데이터 저장: `테이블`, `인덱스`, `뷰`
      - 데이터 조작: `트리거`, `프로시저`, `함수` 등
    - 스키마의 정의
      - 스키마 == 데이터베이스
      - 한 조직의 데이터베이스 시스템의 운영에 필요한 테이블, 인덱스, 뷰 등 데이터베이스 객체의 집합
      - 스키마 관리 방법
      - Forward Engineer
      - SQL 에디터
      - 내비게이터 패널
  - 데이터가 준수해야 하는 `제약조건`을 기술
  - 스키마/데이터베이스 생성/삭제
    - CREATE schema 스키마명
    - DROP schema 스키마명
  - e.g. CREATE, ALTER, DROP
  
- `데이터베이스 조작 언어(DML: Data Manipulation Language)`
  - DDL에 의해 정의된 테이블에 데이터를 조작하는 명령어의 집합
  - e.g. CRUD

### 데이터 타입

- 컬럼이 가질 수 있는 값의 범위, 즉 `도메인`을 결정

- char vs varchar
  - char: 데이터 메모리가 정해져 있다. 
  - varchar: 데이터 메모리가 변한다. 
  
- text, clob: 길이가 최대  2~4gb인 가변길이 문자열
- enum: 유한개의 문자열 집합 중 하나의 값을 선택
  - 성별: enum(‘남’, ‘여’)
  - 혈액형: enum(‘A’, ‘B’, ‘C’, ‘D’)

### 제약조건

- **테이블과 테이블에 존재하는 데이터를 보다 무결하게 관리하기 위한 목적으로 사용**
- DBMS는 테이블 조작 시 테이블에 정의된 제약조건을 만족시키는지 지속적으로 검사
- DBMS는 적용하려는 제약의 유형에 따라 다양한 제약조건을 지원
  
- PK(Primary Key): unique + not null
- FK(Foreign Key): 다른 테이블의 기본키(참조 무결성 보장)
- NOT NULL
- UNIQUE: 중복된 값 허락 X
- AUTO_INCREMENT
- CHECK: 열에 입력되는 값을 검사하여 특정 조건 준수 여부 확인

### 중첩 질의 

- subquery

### 조인 질의

- ER모델링 및 정규화 기법
- 여러 테이블로 분리된 정보를 통합하여 검색 시 유용

<br/>

***SQL***

```sql
select 학생.학생이름
  , 학생.나이
  , 계좌.계좌번호
  , 계좌.잔액
from 학생 inner join 계좌 on 학생.학생번호 = 계좌.학생번호
where 학생.나이 >= 30;
```

<br/>

***SQL(Oracle)***

```sql
select 학생.학생이름
  , 학생.나이
  , 계좌.계좌번호
  , 계좌.잔액
from 학생, 계좌 
where 학생.학생번호 = 계좌.학생번호 and 학생.나이 >= 30;
```

<br/>

- 자연 조인(Nature join: on 사용 x)
  - 두개 이상의 테이블을 하나의 테이블로 결합하는 내부 조인과 매우 유사한 기능
  - 두 테이블에 동일한 이름의 컬럼에 대해 값이 같은 레코드를 결합하는 내부 조인
```sql 
select 컬럼1, 컬럼2, ... 컬럼n
from 테이블1 nature join 테이블2
[where 조건]
```

<br/>

- 셀프 조인
  - 한 테이블이 자기 자신과 조인되는 형태
  - 동일한 이름의 테이블에 대한 조인이므로 반드시 테이블 이름에 대한 별칭이 의무적으로 사용

### 뷰(View)

- 데이터를 저장하고 있는 하나 이상의 테이블을 유도하여 생성하는 가상의 테이블(virtual table)
- `데이터 독립성`: 원본 테이블의 구조가 바뀌어도 뷰를 이용한 작업은 정의만 변경되어 응용프로그램에 영향이 없다.
- `데이터 보안`: 사용자에게 원본 테이블의 일부 컬럼에 대한 접근을 허용하여 보안 효과를 향상시킨다.
- 다양한 구조의 테이블 사용: 사용자의 요구사항에 맞는 테이블의 구조를 제공한다.
- `작업의 단순화`: 복합한 질의 문을 뷰로 단순화한다.
- `데이터 무결성`: with check option 을 이용하여 뷰 생성에 위배되는 수정작업을 거부한다. 테이블이 생성되지는 않지만 테이블처럼 사용 가능하다. 
  
```sql
create view 뷰이름 as 
( select 컬럼1, 컬럼2, ... 컬럼n from 테이블 [where 조건] )
[with check option]
```

<br/>
<hr>

# 7강. 정규화

### 좋은 릴레이션과 나쁜 릴레이션

- 잘못된 데이터베이스 모델링 
  - <img src="/assets/img/knou_database_system/8.png" width="400px"> 
  - 데이터의 부분적인 중복
    - 일관성 유지 어려움.
    - 저장 공간 낭비
  - 갱신 이상
    - 삽입 이상: 레코드 추가 시 불필요한 컬럼의 값이 없이는 추가하지 못 하는 경우
    - 삭제 이상: 삭제 시 의도하지 않았던 다른 데이터가 삭제되는 경우
    - 수정 이상: 중복 저장된 레코드를 수정 시 모두 반영이 안되어 데이터베이스의 일관성이 깨지는 경우.
  
- 좋은 릴레이션의 개념
  - 릴레이션의 스키마가 얼마나 효율적으로 실세계를 반영
  - <img src="/assets/img/knou_database_system/9.png" width="600px"> 
  - 고려사항
    - 한 릴레이션 내의 컬럼 간의 관계 분석
    - 원하지 않는 데이터의 종속과 중복 제거
    - 새로운 컬럼들이 데이터베이스에 추가될 때, 기존 컬럼과 관계 수정을 최소화

### 함수의 종속성

- 정의
  - 릴레이션 인스턴스를 분석하여 속성들 간의 연관관계를 표현한 것
  - 릴레이션의 효율성을 향상시켜 좋은 릴레이션으로 변환하는데 이용되는 중요한 개념
  - <img src="/assets/img/knou_database_system/10.png" width="400px"> 
  - a컬럼의 값이 같으면 b컬럼의 값은 같다. 
  - 등급이 할인율을 종속한다.
  - 등급: 결정자
  - 할인율: 종속자
  
- 함수적 종속성의 확장
  - 함수적 종속성은 릴레이션의 효율성 여부에 중요한 판단기준이다. 
  - 릴레이션의 인스턴스만으로 내재된 모든 함수적 종속성을 찾아내기 어렵다. 
  - 판별되지 않은 모든 함수적 종속성을 찾기 위해 추론 규칙을 사용하여 함수적 종속성을 확장한다. 
  - 클로저(closure)
    - 판별된 함수적 종속성 집합으로부터 유추할 수 있는 모든 함수적 종속성 집합
  
- 함수의 종속성 판별
  - <img src="/assets/img/knou_database_system/8.png" width="400px"> 
  - 결정자                    종속자
  - 고객번호 →                고객명
  - 고객병 →                  등급
  - {고객번호, 고객명} →       할인율
  - 고객번호 →                {고객명, 등급, 할인율}
  
- 암스트롱 공리
  - 재귀 규칙: X ⊇ Y 이면, X → Y
  - 부가 규칙: X → Y 이면, XZ → YZ
  - 이행 규칙: X → Y 이고 Y → Z 이면, X → Z
  - 분해 규칙: X → YZ 이면, X → Y 
  - 합집합 규칙: X → Y 이고, X → Z 이면, X → YZ
  - 의사 이행성 규칙: X → Y 이고, WY → Z 이면, WX → Z 
  
- 카노니컬 커버
  - 함수적 종속성 추런 규칙으로 확장된 클로저에는 자명한 종속성과 중복된 종속성을 포함
  - 불필요한 함수적 종속성을 제거한 표준형으로 변환 후 정규화를 수행

### 정규화

- `정규형`: **이상 현상을 최소화하도록 특정 조건을 갖춘 릴레이션의 형식**
  
- 정규형의 분류
  - 제 1정규형 > 제 2정규형 > 제 3정규형 > BC 정규형 > 제 4정규형 > 제 5정규형
  - (대부분 제 4/5정규형까지 도달하지 않는다.)
  
- `정규화`: **특정 정규형의 조건을 만족하도록 릴레이션과 속성을 재구성하는 과정**
  
- 정규화의 기능
  - 데이터베이스 내 모든 릴레이션을 효과적으로 표현
  - 보다 간단한 관계연산에 기초하여 검색 알고리즘을 효과적으로 작성할 수 있도록 지원
  - 바람직하지 않은 삽입, 수정, 삭제 등의 이상 발생 방지
  - 새로운 형태의 데이터가 삽입될 때 릴레이션 재구성의 필요성을 축소
  
- 제 1정규화
  - 원자성을 만족해야 한다. 
  - `원자성`: 한 컬럼의 값은 하나이어야 한다.
  - <img src="/assets/img/knou_database_system/11.png" width="600px"> 
  
- 제 2정규화
  - 제 1정규화 + 기본키를 제외한 컬럼들은 모두 기본키에 종속
  - <img src="/assets/img/knou_database_system/12.png" width="600px"> 
  - <img src="/assets/img/knou_database_system/13.png" width="600px"> 
  
- 제 3정규화
  - 제 2정규화 + 기본키가 아닌 속성들이 어떤 키에도 이행적 종속성이 없는 하는 상태
  - (기본키를 제외한 컬럼들 중 한 컬럼이 다른 컬럼을 종속하는 경우)
  - <img src="/assets/img/knou_database_system/14.png" width="600px"> 
  
- BC정규화
  - 제 3정규형 + x → y 를 종속한다라는 모든 상태에 대해서 x는 수퍼키여야 한다. 
  - {도크번호, 입항시간} → {목적}
  - {도크번호, 입항시간} → {출항시간}
  - {목적} → {도크번호}: 목적은 기본키가 아님에도불구하고 결정자인 상태(BC정규화 필요)
  - <img src="/assets/img/knou_database_system/15.png" width="600px"> 
  
- 정규형 결과
  - <img src="/assets/img/knou_database_system/16.png" width="600px"> 
  
- ***정리***
  - `정규화`
    - 릴레이션 분할을 통해 `데이터의 중복성을 최소화` 하는 과정
    - 사용 과정에서 많은 `조인 연산 유발`
  - `반정규화`
    - 정규화를 통해 분리되었던 `릴레이션을 통합`하는 재조정을 수행하고 정보의 `부분적 중복을 허용`하는 기법
    - 데이터 접근 성능을 개선 목적

<br/>
<hr>

# 9강. 데이터 저장과 파일

### 물리적 저장장치

- 데이터 접근 속도, 용량을 기준으로 다양한 장치로 구성
- <img src="/assets/img/knou_database_system/17.png" width="600px"> 
- 휘발성
  - 캐시: 고비용 저장장치로 빠른 접근속도 보장
  - 메인 메모리: 실제 프로그램과 데이터 적재 공간
- 비휘발성
  - 자기디스크: 데이터베이스 전체를 안정적으로 저장
  - 플래시 메모리: 메인 메모리와 유사하나 비휘발성
  - 자기 테이프: 용량이 크고 저렴하나 순차 접근 방식으로 접근하여 속도가 매우 느림
  - 광학 디스크: CD, DVD, Blue-ray 등..

### 파일

- 하나의 릴레이션은 여러 개의 블록으로 나뉘어 저장된다. 
- <img src="/assets/img/knou_database_system/18.png" width="600px"> 
- 파일
  - 데이터를 영구적으로 저장하기 위해 사용되는 가장 기초적인 논리적 구조
- 블록 
  - 파일을 고정적인 길이로 분할하여 생기는 균등한 크기의 데이터 묶음
  - 일반적으로 메모리와 디스크 간 데이터 전송 단위로 결정
- 레코드
  - 블록을 구성하는 요소
  - 더 이상 분리될 수 없는 최소 데이터 저장 단위
  
- `고정 길이 레코드`
  - <img src="/assets/img/knou_database_system/19.png" width="400px"> 
  - 모든 레코드가 40byte 크기로 구성될 때, i 번째 레코드 접근
  - (i - 1) * 40 + 1 번째 바이트부터 40개의 바이트를 읽어 접근
- 고정 길이 레코드 할당
  1. 블록의 길이가 레코드 길이로 정확히 나눠지지 않아 잔여 공간을 비워두는 방법
    <img src="/assets/img/knou_database_system/20.png" width="400px"> 
  2. 블록의 길이가 레코드 길이로 정확히 나눠지지 않아 한 레코드를 두 블록에 나누어 저장하는 방법
    <img src="/assets/img/knou_database_system/21.png" width="400px"> 

- 고정 길이 레코드 할당 문제점
  - 레코드 삭제 시 해당 레코드가 저장된 위치에 빈 공간이 생성
  - 장시간 레코드의 삽입 및 삭제 발생 시, 저장 공간에 많은 낭비 발생

- 레코드 삭제시 대처 방안
  - 마지막 레코드로 공백 대체
  - 삭제 레코드 이후의 레코드를 이동
  - 가용 리스트 관리
    - 파일의 헤더에 공백 레코드 포인터를 집어 넣어 특정 행 삭제시, 공백 레코드 포인터가 빈 행에 대한 링크를 가지고 있는다. 새로운 레코드 삽입 시 공백 레코드 포인터를 활용하여 빈 행에 레코드를 삽입한다. (연결 리스트 활용)

- `가변 길이 레코드`
  - 블록에 저장되는 레코드의 길이가 서로 다른(가변적) 레코드를 할당하는 방법
- 가변 길이 레코드가 사용되는 상황
  - 하나의 블록에 두 개 이상의 레코드가 있을 때 
  - 길이가 고정되지 않은 컬럼의 개수가 하나 이상일 때 
  - 레코드가 멀티셋을 허용한 컬럼을 가질 때
  - `멀티셋`: 레코드의 컬럼 값이 여러 개인 컬럼 (원자성에 어긋남)
  - <img src="/assets/img/knou_database_system/22.png" width="400px"> 
  - 해당 행에 대한 정보 + 고정길이 컬럼들 + NULL + 가변길이 컬럼들
  - <img src="/assets/img/knou_database_system/23.png" width="600px">
  - 하나의 블록 내부에 여러 레코드가 쌓이는 가변 길이 레코드는 슬롯 페이지 구조를 사용하며, 레코드가 마지막 공간부터 차곡차곡 쌓인다. 
  
- 파일 구조화: 파일 수준에서 레코드를 관리하는 기법
  
- 파일 구조화 방법의 종류
  - 새로운 행 삽입시, 
    - `힙 파일 구조저장`
      - 순서 고려없이 파일 내 빈 공간 임의의 위치에 저장
      - 가장 빠른 저장속도
      - 좋지 않은 조회성능
    - `순차 파일 구조`
      - 레코드들이 탐색키 기준으로 정렬되어 저장
      - 힙 파일 구조보다는 저장속도가 느림
      - 빠른 조회성능 with `이진 탐색 트리방식`
      - 가장 많이 사용되는 구조
    - `해시 파일구조`
      - 해시 함수를 사용하여 블록 주소를 계산하여 저장
  
- 순차 파일 구조
  - 레코드가 검색키 순서대로 정렬
  - 레코드가 파일에 삽입되는 시점에 키 값이 부여
  
- 순차 파일 구조의 장점
  - 검색키에 대한 정렬 연산이 필요없다. 
  - 현재 레코드에서 정렬된 키 순서로 다음 레코드를 찾을 때 부가적인 블록 접근이 불필요하다.
  - 이진 탐색을 사용하면 더 빠른 레코드 검색이 가능하다. 
- 순차 파일 구조의 단점
  - **레코드 삽입, 삭제에 많은 비용이 소모된다.** 
  
- `오버플로우 블록`
  - 저장의 방식을 개선하기 위해 오버플로우 블록을 사용하기도 한다. 
  - 순차 파일 구조에서 레코드의 정렬된 상태를 유지하기 위해 삽입된 신규 블록

### 저장장치 관리

- 저장장치 접근
  - 파일은 논리적 관점에서의 저장 객체
  - 실제 저장될 때에는 여러 개의 물리적 단위인 블록으로 저장
    - **블록은 메모리와 디스크 간 데이터의 전송 단위**
    - 일반적으로 2KB ~ 32KB 사용
    - **블록 전송을 최소화 할수록 입출력 소요 시간이 단축된다.** 
      - 사용 중인 블록을 지속적으로 메모리에 적재한다.
      - (디스크는 느리니까 한 번 읽은 블록은 여러번 재사용 할 수 있게한다.)
      - 한정적 공간으로 인하여 필요에 따라 특정 블록 할당을 해지한다.  
      - 메모리 내부에 `버퍼`라는 공간에 블록을 저장하고, 이를 관리하기 위해 `버퍼 관리자`를 사용한다.(디스크와 메인 메모리 사이에 버퍼를 두고 버퍼관리자가 관리)
  
- `버퍼관리자`
  1. 소프트웨어가 블록 요청
  2. 버퍼 관리자가 메인 메모리를 탐색하여 블록을 찾아 전달
  3. 블록이 없다면, 디스크로가서 해당 블록을 찾아 메모리에 전달 후 응답
    - 메모리에 블록을 전달 시 메모리의 공간이 꽉 차있을 경우, 메모리 중에 비어있는 데이터를 디스크로 내보내고 필요한 블록을 메모리에 적재한다.
  
- ***메모리의 공간이 꽉 차있을 경우, 버퍼 관리자는 메모리 내 어떤 블록을 비울까?***  
  - 버퍼 교체 전략
    - 가장 쓰임이 덜할 것 같은 블록을 디스크에 보냄(어떤 교체전략이 좋다 이런 것은 없음)
    1. `LRU(Least Recently Used)`: 최근에 가장 적게 사용된 블록을 교체
    2. `MFU(Most Frequently Used)`: 특정 기간동안 가장 여러번 사용된 블록을 교체
  
- `고정 블록과 블록 강제 출력`  
  - **메모리 내 블록을 고정 하여 버퍼관리자에 의해 해당 블록이 나가는 것을 막는다.** 
  - 고정블록
    - 메모리 내 고정되어 있는 블록
  - 블록 강제 출력
    - 메모리 내 블록 중 <u>강제로 디스크에 내보내는 것</u>
    - 메인 메모리는 휘발성이기에 전원이 나가거나 서버연결이 끊길 시 중요한 블록이 소실될 수 있기에 영구저장장치인 디스크로 내보낸다.

<br/>
<hr>

# 10강. 인덱싱

### 인덱싱의 이해

- 블록 요청 → 디스크 내 데이터 메모리 할당 → 응답
- `인덱스`
  - 디스크와 메모리 사이의 입/출력을 줄일 수 있는 기능
  - DBMS에서 요청된 레코드에 빠르게 접근할 수 있도록 지원하는 데이터와 관련된 부가적인 구조
- 인덱싱: 인덱스를 구성하고 생성하는 작업
  
- 인덱스 활용: 인덱스의 탐색키를 이용하여 해당 래코드가 저장된 블록을 디스크 저장장치 / 메모리에서 파악하여 해당 블록을 빠르게 적재한다. 
- `탐색키`: 파일에서 레코드를 찾는데 사용되는 컬럼/컬럼의 집합
  
- 인덱스 기반의 검색 과정
  1. 디스크에 저장된 모든 인덱스 블록을 메모리에 적재(모든 레코드 블록을 한 번에 적재하기는 어렵지만, 인덱스 블록은 메모리가 훨씬 작아 모든 인덱스 블록을 올리기가 가능)
  2. 해당 레코드 블록을 찾아 응답
  
- 인덱스의 종류
  - `순서 인덱스`: 특정 값에 대해 정렬된 순서 구조
  - `해시 인덱스`: 해시 함수를 이용해서 저장에 대한 순서를 결정하는 구조
  
- 인덱스 평가기준
  - 접근시간: 데이터를 찾는데 걸리는 시간
  - 유지비용: 데이터를 삽입/삭제 연산으로 인한 인덱스 구조 갱신 비용
  - 공간비용: 인덱스 구조에 의해서 사용되는 부가적인 공간 비용

### 순서 인덱스

- 순서 인덱스의 특징
  - 탐색 키로 정렬된 순차 파일에 대하여 레코드에 대한 빠른 접근이 가능하도록 구성한 인덱스
  - 탐색 키를 정렬하여 해당 탐색 키와 탐색 키에 대한 레코드와의 연계를 통하여 인덱스 생성(탐색 키가 순차적으로 정렬되어 있다.)
  
- 인덱스 엔트리 구조
  - <img src="/assets/img/knou_database_system/24.png" width="400px">
  - 오프셋: 블록 b2에서 30byte 뒤에 위치
  
- 순서 인덱스 종류
  - 밀집 인덱스
    - <img src="/assets/img/knou_database_system/25.png" width="400px">
    - 모든 레코드에 대해 인덱스 엔트리를 유지하는 인덱스
  - 희소 인덱스
    - <img src="/assets/img/knou_database_system/26.png" width="400px">
    - 인덱스 엔트리가 일부 탐색키 값만을 유지
    - COM31을 찾을 경우 COM31보다 작은 탐색키중 가장 큰 탐색키(COM11)을 통해서 다시 순차적으로 COM11에서부터 데이터를 찾는다.
  - 다단계 인덱스(밀집 인덱스의 밀집인덱스: 밀집인덱스 + 희소 인덱스)
    - <img src="/assets/img/knou_database_system/27.png" width="400px">
    - 밀집 인덱스는 상대적으로 많은 데이터 저장공간을 요하기에 다단계 인덱스가 등장
    - 인덱스 크기 < 메모리 크기: 디스크 I/O이 줄어 탐색시간이 축소된다. 
    - 인덱스 크기 > 메모리 크기: 저장된 블록을 여러번 나누어 읽어야 하기 때문에 디스크 I/O 비용이 증가하여 탐색 시간이 증가한다. 이럴 경우 전체 인덱스에 대한 인덱스를 다시 만들어서 크기를 줄여 활용한다.
    - e.g. 내부 인덱스는 1,000,000개의 블록을 갖는 반면, 외부 인덱스는 100개의 블록만 사용하여 작은 크기의 외부 인덱스로 메모리에 적재 가능

### B+ Tree 인덱스(이진탐색트리를 다단계 인덱스와 결합)

***이진 탐색 트리(Binary Search Tree)***  
<img src="/assets/img/knou_database_system/29.png" width="400px">
  
***B+ Tree 구조***
- <img src="/assets/img/knou_database_system/28.png" width="400px">
- 탐색키 2개가 묶인 B+트리구조
- `단말노드`(제일 하단 노드)는 서로 연결되어 있는 `연결 리스트 형태`
  
- `B+트리 인덱스`
  - 루트노드로 부터 모든 단말노드에 이르는 경로의 길이가 같은 높이 균형 트리
  - 순서 인덱스는 파일이 커질수록 데이터 탐색에 있어서 접근 비용이 커지는 문제점을 해결하기 위해 제안되었다. 
  - 상용 DBMS에서도 널리 사용되는 대표적인 순서 인덱스  
  
- B+트리 노드 구조
  - <img src="/assets/img/knou_database_system/30.png" width="400px">
  - P: 팬아웃(fanout)
  - 팬아웃 20개 == 노드의 하위 노드가 20개
  
- B+트리 구성 요소
  - `인덱스 세트`
    - 구성: 루트노드 + 중간노드 
    - 단말노드의 탐색키 값을 신속하게 찾을 수 있도록 경로를 제공하는 목적으로 사용
    - n/2 ~ n 사이의 개수를 자식으로 소유
    - 포인터(화살표)는 실제 레코드를 지칭하지 않고 하위 노드를 가르킨다.
  - `순차 세트`
    - 구성: 단말노드
    - 모든 노드가 순차적으로 서로 연결
    - 단말노드는 적어도 (n-1)/2 개의 탐색키를 포함
    - 단말노드만 실제 레코드를 지칭하는 `포인터` 제공
  
- 'COM44'의 과목명은?
  - <img src="/assets/img/knou_database_system/31.png" width="600px">
  1. COM44와 같거나 큰 것들 중에서 가장 작은 노드를 찾는다. 
  2. 아무 것도 없으면 가장 오른쪽 포인터를 따라서 찾는다. 
  3. 단말 노드에서 탐색 키를 찾으면 실제 레코드를 지칭하는 포인터를 따라 실제 레코드에 접근한다. 
  4. 디스크에서 찾은 레코드를 메모리에 올려서 사용자에게 응답한다. 
  
- 'COM24' 삽입
  - <img src="/assets/img/knou_database_system/32.png" width="400px">
  - 'COM12', 'COM31' 분할
  - 우측 단말 노드에 'COM24' 삽입
  
- 'COM12' 삭제
  - <img src="/assets/img/knou_database_system/33.png" width="400px">
  - 해당 단말 노드 삭제 후 탐색키 존재 x
  - <img src="/assets/img/knou_database_system/34.png" width="400px">
  - 'COM12'가 저장된 노드의 오른쪽 형제 노드와 키 재분배

<br/>
<hr>

# 11강. 해싱과 특수 인덱스

- 해시(Hash)
  - 해시 함수를 통해 버킷ID 내 몇 번째에 들어가야하는지 결정
  - 해시 함수를 사용하여 데이터 배분 및 접근
  - `해시 함수`: 탐색 키에 산술적인 연산을 통해 버킷의 주소를 계산
  
- 버킷(Bucket)
  - 한 개 이상의 레코드를 저장할 수 있는 저장공간의 단위
  - 크기는 일반적으로 디스크 블록의 크기와 일치(블록과 동일한 개념)
  
- 해시 함수의 역할
  - <img src="/assets/img/knou_database_system/35.png" width="400px">
  - 해시 함수는 버킷ID 반환
  
- <img src="/assets/img/knou_database_system/36.png" width="600px">

### 정적해싱

- 버킷의 개수가 고정된 해싱 기법
  
- 충돌: 다른 레코드가 해시 함수를 통해 동일한 버킷에 대응
- 동거자: 충돌에 의해 같은 버킷 주소를 갖는 레코드들
  
- `오버플로(Overflow)`
  - 충돌이 많아지면 다수의 동거자 발생 → 오버플로 현상
  - 버킷이 레코드로 가득 차 있을 경우 발생
  - 추가적인 버킷 할당 / 다음 버킷에 할당하여 처리
  - 오버플로우가 발생할수록 다른 버킷에 접근해야한다. 즉, **접근시간이 길어져 성능 저하**
  - 오버플로우가 발생하는 해시함수 지양할 것
  
- 해시 인덱스
  - 해시 파일 구조와 동작 방식을 레코드가 아닌 인덱스 엔트리에 적용한 인덱스
  - <img src="/assets/img/knou_database_system/37.png" width="600px">
  - 인덱스 엔트리를 해싱
  - 버킷에 해시 인덱스를 저장(레코드 저장 x)
  
- 정적해싱의 문제
  - 데이터베이스의 크기가 커짐에 따른 성능 감소(오버플로우)
  - 미리 큰 공간을 잡을 경우, 초기 공간 낭비
  - 재구성 시 새롭게 선택된 해시 함수를 사용하여 모든 레코드에 대해 다시 계산하고 버킷에 할당하는 대량의 비용 발생

### 동적해싱

- 버킷의 개수를 데이터 개수에 맞게 조절
- 버킷의 개수를 가변적으로 조절하는 해싱 기법
- 데이터베이스의 크기에 따라 버킷의 크기가 비례
- 데이터베이스의 증대/축소에 따른 인덱스의 구조를 조절하기 위해 해시 함수를 동적으로 변경하는 기술
  
- 확장성 해싱
  - 구조: 디렉토리, 버킷
  - 디렉토리: 디스크에 저장되는 버킷 주소 테이블
  - 정수값 d: 디렉토리 깊이 
  - 디렉토리 깊이를 의미하는 정수값 d를 포함하는 헤더와 데이터가 저장된 버킷에 대한 2**d개의 포인터로 구성
  - 디렉토리를 거쳐야만 버킷에 접근 가능

  - 모조키(Pseudo Key)
    - 레코드의 `탐색키 값`이 해시 함수에 의해 일정 길이의 `비트 스트링`으로 변환된 키 
    - (모조키가 버킷ID를 의미하는 것은 아니다.)
    - 모조키의 첫 d 비트를 사용하여 디렉토리에 접근
  - 버킷 헤더
    - 정적해싱이 가지고 있는 저장고간을 가짐
    - 모조키의 앞부분의 몇비트가 일치하는 개수를 담고 있음
    - 버킷에 저장되어 있는 레코드의 모조키들이 처음부터 i비트까지 일치함을 표시
  
- 확장성 해싱 구조
  - <img src="/assets/img/knou_database_system/38.png" width="600px">
  - 3: 헤더, 모조키의 앞 3비트를 보겠다.
  - 확장성 해싱 구조 순서
    1. K3 탐색 키가 있고 사용자가 해당 레코드를 요청하였을 때, (검색)
    2. h(K3): 해시 함수에 K3를 넣고 
    3. 모조키 101000010001 를 얻었다. 
    4. 모조키의 앞 3자리를 보면 101 이고, 
    5. 디렉토리 밑에서 3번째 101을 거쳐 버킷 B4에서 해당 레코드를 찾을 수 있다. 
  
  - 해당 모조키 101000010001 를 삽입할 경우
    - 조회와 동일하게 B4 버킷으로 가게 되고
    - 해당 버킷이 가득 찼을 때, 정적해싱의 경우에는 다른 버킷을 생성하거나 다음 버킷으로 기능을 위임했지만, 동적해싱의 경우에는 버킷을 하나 더 추가하여 배분한다. 
  
- 데이터가 급속도록 많이 늘어날 수 있는 테이블은 동적해싱
- 레코드의 개수가 유지되는 테이블은 정적해싱

### 비트맵 인덱스

- 탐색 키의 중복 비율이 높은 컬럼을 대상으로하는 질의를 효율적으로 처리하기 위해 고안된 특수한 형태의 인덱스
  
- 비트맵: 간단한 비트 배열
  
- 비트맵 인덱스 구성
  - <img src="/assets/img/knou_database_system/39.png" width="400px">
  - i번째 레코드가 컬럼 A에 해당 값을 가지면 비트맵의 i번째 비트를 1, 그렇지 않으면 0
  - 해당 컬럼에 들어갈 수 있는 값만큼 비트열이 생성
  - 남자 비트열: 100101
  - 여자 비트열: 011010
  
- 성별이 남자이고 성적이 B인 레코드 조회 시
  - 성별이 남자인 비트맵: 100101 & 성적이 B인 비트맵: 100100
  - 100100
  
- 비트맵 인덱스의 특징
  - 비트맵 활용
    - 컬럼에 대한 값의 범위가 유한하고 비교적 개수가 적은 규모일 때 용이
    - 적용: 직책, 학과, 혈액형 등..
  - 비트맵 인덱스의 크기
    - 레코드의 크기가 수백 바이트 이상이 되어도 비트맵 인덱스에서는 하나의 비트로 표시하기 때문에 용량이 작다. `작은 용량`
    - 실제 릴레이션 크기에 비해 매우 작은 것이 장점이다. 

<br/>
<hr>

# 12강. 트랜잭션

### 트랜잭션의 이해

- 데이터 동시 접근의 문제: 동일 데이터에 다수 사용자의 접근 허용 시 일관성이 훼손
  
- 트랜잭션의 개념: 데이터베이스를 조작하기 위한 하나의 논리적 단위를 이루는 일련의 연산의 집합
  
- 트랜잭션의 특징
  - <img src="/assets/img/knou_database_system/40.png" width="600px">
  - `A` 원자성(Atomicity): 하나의 트랜잭션에 포함된 모든 연산은 완전히 수행 / 수행 x
  - `C` 일관성(Consistency): 트랜잭션이 수행되기 전 / 후 일관된 상태 유지
  - `I` 고립성(Isolation): 특정 트랜잭션 실행 중 다른 트랜잭션의 방해를 받지 않음
  - `D` 지속성(Durability): 완료된 트랜잭션의 결과는 시스템 장애가 있더라도 반영이 되어야 함
  
- 트랜잭션의 두 연산
  - Read(X): 데이터베이스에서 데이터 X를 읽고, 트랜잭션이 실행되는 메모리의 변수 X에 값을 저장하는 연산
  - Write(X): 트랜잭션이 실행되는 메모리에 있는 변수 X의 값을 데이터베이스에 저장하는 연산
  
- 트랜잭션 5가지 상태 변화
  - <img src="/assets/img/knou_database_system/41.png" width="400px">
  - active(동작): 요청이 와서 비지니스 로직 실행
  - particially committed(부분 커밋): `트랜잭션 메모리에만 저장`이 된 상태. DB에 저장되지 않은 상태
  - committed(커밋): DB에 저장된 상태
  - failed(실패): 트랜잭션 처리 중 실패
  - aborted(중단): 실패 시 롤백되어 이전 상태로 환원된 상태

### 트랜잭션의 동시성

- 동시성 고려: DBMS는 다수의 사용자가 데이터베이스를 공용으로 사용하기 위한 목적으로 도입
  
- 트랜잭션 동시 실행의 이점
  - 트랜잭션 처리율과 자원 이용률을 향상
  - 트랜잭션의 대기 시간을 감소
  
- 동시성 제어(Concurrency Control)
  - 다수의 트랜잭션이 성공적으로 동시에 실행되어도 일관성을 유지할 수 있도록 지원하는 기법
  - 동시에 처리했지만 동시에 처리하지 않은 결과를 보장
  
- 동시성 제어를 어떻게 할까?
  - `스케줄(Schedule)`: 다수의 트랜잭션에 포함된 연산의 실행 순서를 명시한 것
  - 스케줄의 순서를 보고 동시에 실행해도 되는지 판별
  
- 직렬 스케줄
  - 각 트랜잭션에 속한 모든 연산이 순차적으로 실행되는 스케줄
  - 일관성 훼손 x
- 병렬 스케줄
  - 하나의 트랜잭션이 완료되기 전에 다른 트랜잭션이 실행되는 스케줄
  - 비순차적으로 실행
  - 일관송 훼손 발생 가능
  - 병렬 스케줄은 일관성을 훼손시키는 가능성이 있으므로 직렬 스케줄로 바꿔야 한다. 
  
- 직렬 가능 스케줄
  - 복수 개의 트랜잭션이 동시에 수행된 결과가 직렬 스케줄의 결과와 동일한 스케줄
  - 즉, 병렬 스케줄의 결과가 직렬 스케줄의 결과가 동일한 스케줄(일관성 훼손 x)
  
- 직렬 가능한 스케줄을 확인
  - read, write 연산 교환하여 실행 결과에 일관성 훼손되는지 파악
  - <img src="/assets/img/knou_database_system/42.png" width="400px">
  - 첫째 줄을 제외한 나머지는 일관성을 훼손
  
- <img src="/assets/img/knou_database_system/43.png" width="400px">
- 같은 작업 A에 대하여 write, read 연산의 순서를 바꿀 시 충돌
- <img src="/assets/img/knou_database_system/44.png" width="400px">
- 서로 다른 작업(A, B) 읽고 쓰기는 교환을 해도 충돌이 나지 않는다. 
- `충돌 동등`: 트랜잭션의 실행 순서를 바꿔도 동일한 결과를 얻는 상황
  
- 충돌 직렬성
  - 순서 교환이 가능한 연산을 교환하여 직렬 스케줄의 연산과 동등하게 변환이 가능한 스케줄

### 트랜잭션의 회복

- 회복의 개념
  - 원자성을 보장하기 위해 트랜잭션 실패 시 실행된 모든 연산을 실행 이전 상태로 복원하는 기법
  - 스케줄은 항상 회복 가능한 스케줄로 구성이 되어야 한다.
  
- 회복 가능한 스케줄
  - Ti 와 Tj 에 대하여, Ti가 기록한 데이터를 Tj가 읽을 때, Ti의 커밋이 Tj보다 먼저 나타나는 스케줄
  - <img src="/assets/img/knou_database_system/45.png" width="400px">
  - 비연쇄적 스케줄
    - 연쇄적 롤백으로 발생할 수 있는 대량의 회복 연산을 방지하기 위해 연쇄적이지 않은 스케줄로 구성된 스케줄
    - 커밋 이후에 read() 실행. 회복 가능하면서도 연쇄적 롤백을 일으키지 않는다. 

  - 연쇄적 롤백 유발 가능한 경우
    - <img src="/assets/img/knou_database_system/46.png" width="400px">
    - T7 롤백으로 인해 연쇄적으로 다른 트랜잭션도 롤백

<br/>
<hr>

# 13강. 동시성 제어

- `트랜잭션 직렬화와 회복화`: 스케줄이 데이터 일관성에 영향을 미치는 여부를 판별하고 일관성이 유지되는 상태로 복원시키기 위해 정의한 개념
  
- 일관성 훼손을 발생시키는 트랜잭션에 대해 동시성 제어를 통하여 일관성 유지에 개입한다.
  - 트랜잭션 간 연산 순서 제어
  - 모든 read(), write() 연선에도 무결성 유지
  - 동시에 실행되는 트랜잭션 수 증가
  
- 동시성 제어 규약
  - 락 기반 규약
  - 타임스탬프 기반 규약
  - 검증 기반 규약

### 락 기반 규약

- 락 기반 규약 개념
  - 직렬 가능성 보장을 위해 락(잠금)을 사용
  - 데이터 항목에 연산 전 트랜잭션이 락을 획득하여 연산 후 반납
  - read / write 연산 시 락을 걸어 다른 트랜잭션의 접근을 막음
  
- 락의 종류
  - 공유 락(LS): 해당 항목에 락을 걸어도 다른 트랜잭션의 공유 락을 허용한다. (읽기 작업할 때 사용)
  - 베타 락(LX): 해당 항목에 먼저 락을 걸으면 다른 트랜잭션은 락을 걸 수 없다. (읽기/쓰기 작업시 사용)
  - 트랜잭션은 연산 전 락 획득이 선행되어야 한다.
  
- 락 반납을 일찍 한 트랜잭션
  - <img src="/assets/img/knou_database_system/47.png" width="400px">
  - T10 계좌 이체 중 T11 트랜잭션이 끼어들어 일관성 훼손 발생
  - T10 이 락을 일찍 반납하여 비일관적인 상태에서 데이터 접근이 가능해져 T11이 정확하지 않은 결과값을 출력하게 됨
  
- 락 반납이 지연된 트랜잭션
  - <img src="/assets/img/knou_database_system/48.png" width="400px">
  - T12 의 언락이 마지막에 실행되므로T13의 트랜잭션이 접근할 때는 베타락이 걸려있는 상태이기 때문에 실행되지 못하고 대기된다.
  - 교착상태
    - T12이 B에 대한 배타 락을 반환할 때까지 T13은 대기
    - T13이 A에 대한 공유락을 반환할 때까지 T12는 대기
  
- 교착상태(Deadlock) 해결
  - 두 트랜잭션 중 하나를 `롤백`
  - 한 트랜잭션이 롤백되면 그 트랜잭션이 획득했던 `모든 락은 반납`
  
- 락을 너무 일찍 반납하면 일관성이 훼손되고 락을 너무 늦게 반납하면 교착상태가 발생하기에,
2단계 락킹 규약이 마련되었다.
- `2단계 락킹 규약`
  - 구성: 락을 요청하는 트랜잭션, 락을 반납하는 트랜잭션
  - 확장 단계: 락을 얻을 수 있으나 반납할 수 없는 단계
  - 축소 단계: 락을 반납할 수는  있지만 새로운 락을 얻을 수는 없는 단계
  - 직렬성을 보장(일관성)하나 교착상태 예방 불가 -> `엄격한 2단계 락킹 규약`으로 보안

### 타임스탬프 기반 규약

- 트랜잭션 실행의 순서를 판단하기 위해 타임스탬프(TS)를 부여
  
- W-TS(Q): Write(Q)를 성공적으로 실행한 트랜잭션 중 가장 큰 타임스탬프
- R-TS(Q): Read(Q)를 성공적으로 실행한 트랜잭션 중 가장 큰 타임스탬프
  
- 타임스탬프 할당 방법
  - 시스템 클럭 값(주로 사용)
  - 논리적 계수기
  
- 타임스탬프 기반 규약의 적용
- <img src="/assets/img/knou_database_system/49.png" width="800px">
  
- 토마스 기록 규칙
- <img src="/assets/img/knou_database_system/50.png" width="400px">
- Ti가 쓰고난 후의 값을 Tj가 읽었어야 하는데 그렇지 않았으므로 롤백을 시켜야했으나 
- <img src="/assets/img/knou_database_system/51.png" width="400px">
- 토마스 기록 규칙에서는 롤백하지 않고 어차피 최종적으로 수행될 Tj: Write(Q)를 수행한다.
  
***타임스탬프 관련해서 교재 읽어보기***  

### 교착 상태

- 특정 트랜잭션 집합 내 속하는 모든 트랜잭션이 집합 내의 다른 트랜잭션을 기다리고 있는 상태
- 두 트랜잭션 중 하나늘 반드시 롤백해야 한다. 
  
- 교착상태 처리 방법
  1. 교착상태 방지 규약 사용
    - 모든 데이터 항목에 대해 락을 설정하는 기법
      - 단점1: 트랜잭션이 시작되기 전에 어떤 데이터에 락을 걸어야 하는지 미리 알기 어렵다.
      - 단점2: 락이 걸린 상태에서 많은 데이터들이 오랫동안 사용되지 않아 데이터 항목에 대한 이용률이 매우 낮아진다. 
    - 타임스탬프를 이용한 선점유 기법
  2. 교착상태 발생이 비교적 높지 않은 시스템의 경우
    - 교착상태 탐지와 회복 기법 사용
      - 대기 그래프
      - 희생자 선정
  
- 타임스탬프 이용
  - Tj가 락을 소유한 데이터 항목을 Ti가 요청하는 상황

    - `wait-die 기법`(비선점유 기반): TS(Ti) < TS(Tj)일 때, Ti가 기다리고 그렇지 않다면 Ti 롤백
    - <img src="/assets/img/knou_database_system/52.png" width="400px">
  
    - `wound-wait 기법`(선점유 기반): TS(Tj) < TS(Ti), Ti가 기다리고 그렇지 않으면 Tj를 롤백하고 락을 이양
    - <img src="/assets/img/knou_database_system/53.png" width="400px">
  
- 교착상태 탐지와 회복: 교착상태 발생이 비교적 높지 않은 시스템의 경우 주기적으로 교착상태를 탐지하고 발생 시 회복 절차를 수행한다. 
  
- 대기 그래프(Wait-For Graph)
- <img src="/assets/img/knou_database_system/54.png" width="400px">
- 대기 그래프에서 교착상태에 빠졌을 경우, 회복절차에 돌입한다.
- T13/T14/T15 트랜잭션 중 어느 하나를 롤백시켜야 교착상태에서 빠져나온다. 
- 셋 중 롤백을 시켜야하는 트랜잭션을 `희생자`라고 한다.
  
- 교착상태의 회복
  - 희생자 선정: 롤백 비용이 가장 적은 트랜잭션을 선택
    - 연산을 수행한 시간과 남은 작업을 마치기 위한 시간(수행한 시간, 수행할 시간)
    - 사용한 데이터와 트랜잭션 실행에 필요한 추가적인 데이터
    - 롤백에 포함되는 트랜잭션의 개수
  - 희생자 롤백: 희생자가 정해졌다면 어느 시점까지 롤백 할 것인지 결정한다. 
    - 전체 롤백 vs 교착상태를 해결하는 지점
    - 모든 트랜잭션의 상태에 대한 정보를 부가적으로 유지
  - 무한정 기다림 해결
    - 같은 트랜잭션이 항상 희생자로 선정되지 않도록 희생자 선정 시 롤백 횟수를 고려한다. 

<br/>
<hr>

# 14강. 회복 시스템

### 회복시스템의 개념

- 회복의 역할  
  1. 예상치 못한 HW 고장 및 SW 오류가 발생  
    사용자의 작업에 대한 안정적 디스크 반영 여부 보장이 불가능  
  2. 오류 발생 이전의 일관된 상태로 데이터베이스를 복원시키는 기법이 요구  
    시스템 내의 고장 원인 검출, DBMS의 안전성 및 신뢰성의 보장  
  
- 시스템 실패의 유형  
  1. 트랜잭션 실패  
    논리적: 잘못된 데이터 입력, 부재, 버퍼 오버플로, 자원 초과 이용  
    시스템적: 운용 시스템의 교착상태  
  2. 시스템 장애  
    시스템의 HW고장, SW 오류  
    주기억장치와 같은 휘발성 저장장치의 내용 손실  
  3. 디스크 실패  
    비휘발성 디스크 저장장치의 손상 및 고장으로 인한 데이터 손실  
  
- 회복 데이터의 구성
  - 백업(Back Up): 전체/일부를 복제하여 회복 데이터를 구성
  - 로그(Log): 데이터 변경 이전/후의 값을 별도의 파일에 기록하는 방식
  
- 데이터 저장 구조
  - 데이터는 디스크와 같은 비휘발성 저장장치에 저장되며, 전체 데이터의 일부만 주기억장치(휘발성)에 상주한다. 
  - 데이터베이스는 데이터를 블록(Block) 단위로 전송하고 블록 단위로 기억장소를 분할한다. 
  - 트랜잭션은 디스크로부터 주기억장치로 데이터를 가져오고, 변경된 데이터는 다시 디스크에 반영된다. 
  - 가져오기, 내보내기 연산은 블록 단위로 실행
  - 물리적 블록: 디스크 상의 블록
  - 버퍼블록: 주기억장치에 임시적으로 상주하는 블록
  
- 데이터 베이스 연산
  - <img src="/assets/img/knou_database_system/55.png" width="400px">
  - Input(X): 물리적 블록 X를 메인 메모리에 적재
  - Output(X): 버퍼 블록 X를 디스크에 저장
  - Input & Output 은 메인 메모리 기준이다. 

### 로그 기반 회복

- 로그 기반 회복의 개념: 데이터베이스가 수행한 모든 수정 작업을 기록한 여러 종류의 로그를 사용하여 회복하는 시스템

- 데이터 항목 변경 과정
  1. `WAL(Write-Ahead Log)`
    - 트랜잭션은 데이터베이스 수정 전, 로그 레코드를 생성하여 기록한다. 
  2. 데이터 항목 변경 과정
    - 트랜잭션이 메인 메모리의 개인 영역에서 여러 연산을 수행한다. 
    - 트랜잭션이 데이터 항목이 존재하는 메인 메모리에 위치한 버퍼 블록의 데이터를 변경한다. 
    - Output 명령을 실행하여 버퍼 블록을 디스크에 기록한다.
  
- 회복 기법에서 로그에 대한 두 연산
  - `Redo`: 디스크의 값이 수정이 되지 않았을 경우 다시 실행시켜 값을 변경시킨다.
  - `Undo`: 디스크의 값이 변경되었으면 이전 값으로 복귀시킨다.
  - 로그에 commit / abort 없으면 Undo	
  - 로그에 commit / abort 있으면 Redo
  
- 데이터베이스 변경과 커밋
  1. 데이터베이스 변경 시 복구 알고리즘의 고려 사항
    - 트랜잭션의 일부 변경 사항이 버퍼 블록에만 반영되고 물리 블록에 기록되지 않은 상태에서 트랜잭션이 커밋되는 상황(디스크에 수정된 값이 반영 안 됨)
    - 트랜잭션이 동작 상태에서 데이터베이스를 수정했으나, 수정 후에 발생한 실패로 취소가 필요한 상황(디스크 내 값이 기록되었지만 기록을 취소하고 싶은 상황)
  2. 트랜잭션 커밋 상황
    - 커밋 로그 레코드가 있으면 커밋된 것으로 간주한다. 
    - 커밋 로그 레코드가 없으면 원복시킨다. 
  
- 회복의 유형
  1. 회복은 트랜잭션에 의해 요청된 갱신 작업이 디스크에 반영되는 시점에 따라 구분된다. 
  2. 지연 갱신 회복(Deferred Update Restore)
    - 부분 커밋까지 디스크 반영을 지연시키고 로그에만 기록
    - 실패 시, 별도의 회복 작업 필요 없이 로그만 수정
    - => 모든 작업은 메모리에서 하고 최종 반영물을 디스크에 반영한다. 
  3. 즉시 갱신 회복(Immediate Update Restore)
    - 갱신 요청을 곧바로 디스크에 반영
    - 실패 시, 디스크에 반영된 갱신 내용을 로그를 바탕으로 회복한다.
  
- 시스템 자애 발생 상황
- <img src="/assets/img/knou_database_system/56.png" width="600px">
- 상황1
  - 지연 갱신 회복: 디스크에 반영이 되지 않았으므로 T1 로그만 삭제하면 된다. 
  - 즉시 갱신 회복: 디스크의 반영이 되어 있을 가능성이 있기에 A값을 확인 후 처리한다. 
- 상황2
  - 지연 갱신 회복
  - T1 이 디스크에 커밋이 되었으므로 A,B의 값을 되돌리고 로그도 삭제한다. 
  - 디스크에 반영이 되지 않았으므로 T2 로그 삭제한다. 
  - 즉시 갱신 회복: 커밋 이전의 값들을 살펴보고 롤백한다. 
- 상황3
  - 모두 커밋되었으므로 지연/즉시 갱신 회복 모두 값을 확인하고 되돌린다.
  
- 체크포인트의 필요
  - 로그 기반 회복 시스템의 한계
  - 로그의 크기는 시간이 지남에 따라 계속 증가하므로 대용량 로그의 탐색 비용이 매우 커진다. 
  - Redo를 해야하는 트랜잭션 중 대부분은 이미 데이터베이스에 반영한다. 
  - 반영된 트랜잭션의 재실행은 시스템 자원의 낭비
  
- 체크포인트로 저장할 때, 
  - 현재 시점에서 메인 메모리의 버퍼 블록에 존재하는 모든 로그 레코드를 안정 저장장치(디스크)로 기록한다. 
  - 수정된 모든 버퍼 블록을 디스크에 반영한다. 
  - 로그 레코드<checkpoint List T> 를 안정한 저장장치에 기록한다. 
    - List T: 체크포인트 시점에 실행 중인 트랜잭션 목록
  - 커밋된 것과 되지 않는 것을 구분한다. 
  
- 체크포인트를 이용한 회복
  1. 로그의 마지막부터 역방향으로 탐색하여 <checkpoint ListT> 레코드를 찾는다.
  2. ListT에 존재하는 <checkpoint ListT> 이후에 실행된 트랜잭션에 대해 Redo와 Undo 연산 수행
    - 로그에 <Ti.commit> 또는 <Ti.abort>가 없는 ListT 안의 모든 트랜잭션을 Undo
    - 로그에 <Ti.commit> 또는 <Ti.abort>가 없는 ListT 안의 모든 트랜잭션을 Redo

### 회복 알고리즘

- 시스템 장애 후 회복 알고리즘
  - Redo 단계
    - 최근의 체크포인트에서부터 순방향 로그 탐색
    - 롤백할 대상 트랜잭션의 Undo 리스트인 ListofUndo를 ListT로 초기화
    - <Ti.start> 발견 시, Ti를 ListofUndo에 추가
    - <Ti.abort>,<Ti.commit> 발견 시 Ti를 Undo 리스트에서 제거
    - => abort, commit 을 발견 시 작업자에게 이미 정상적으로 완료되었다고 말한 것이므로 Undo 리스트에서 제거해야 한다. 
  - Undo 단계
    - ListofUndo의 트랜잭션의 로그 레코드를 찾으면 트랜잭션 롤백 알고리즘 1단계 수행
    - ListofUndo의 트랜잭션 Ti에 대해 <T1.start>를 만나면 로그에 <Ti.abort>를 기록하고 ListofUndo에서 제거
    - ListofUndo에 트랜잭션이 존재하지 않는 상태가 되면 Undo 단계 종료

- <img src="/assets/img/knou_database_system/56.png" width="600px">
- Redo 단계
  1. 밑에서부터 역방향으로 체크포인트를 찾으러 올라간다. 
  2. ListofUndo 리스트 생성{T0, T2}후 순방향으로 로그를 확인한다. 
  3. T1 커밋 로그가 있으므로 ListofUndo 리스트에서 T1을 제거한다. 
  4. 이 후 T2가 시작되므로 ListofUndo {T0, T2} 가 되고
  5. T0 가 abort 되었으므로 ListofUndo {T2} 가 된다. 
- Undo 단계
  6. 역방향으로 올라가면서 T2 값을 롤백(<T2, A, 300>)하고 T2 start를 발견하면 abort를 해주며 ListofUndo 리스트에 T2를 제거한다.  
  7. 회복시스템 끝

<br/>
<hr>

# Quiz



